# -*- coding: utf-8 -*-
"""Preprocesamiento.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UdJVUkk_uDR0TO3BJQtA-fNZdWHtTK72

# Data loading.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
import seaborn as sns
from datetime import datetime, timezone
from methods import *

"""Change "filepath" to where the csv file is stored on personal google drive."""

path = "./dataset/reduced_unnamed.csv"
dataset = pd.read_csv(path)
times = dataset["Arrival_Time"]

dataset = dataset.drop(["Creation_Time", "Arrival_Time"], axis=1)
# Interarrivals are in the range 9-11 millliseconds.

S_DS = dataset

# S_DS = dataset.head(len(dataset)/3)
# Convert timestamp to date.
for i in range(len(times)):
    times[i] = datetime.fromtimestamp(times[i]/1e9, tz=timezone.utc)

S_DS["Realtime"] = times

# Remove nan values on classes.
# df.drop(df[df.score < 50].index, inplace=True)
print("Null class row: ")
print(S_DS[S_DS["Index"] == 118469])
nanrows = S_DS[S_DS["gt"].isna()]
print("NAN DATA: \n", nanrows)
S_DS = S_DS.drop(nanrows.index, inplace=False)

print("Dataset: \n")
print(S_DS)

# 1880 seconds passed, approx 150 samples per second per device.
print(len(dataset["Realtime"].unique()))
print(len(dataset["Device"].unique())) # five devices
devices = dataset["Device"].unique()
print(len(dataset["User"].unique())) # 1 User.
print(len(dataset["gt"].unique())) # 7 Activities

"""# Preprocessing """

""" # Get data per device (Not relevant for classification yet)
    Merely for test description info.
"""

data_per_device = {}
for i in range(len(devices)):
    d = devices[i]
    data = dataset[dataset["Device"] == d] 
    data_per_device[d] = data
    # print("******* DEVICE: ", d)
    # print("Data: \n", data)
    seconds = len(data["Realtime"].unique())
    # print("Data sampled for %d seconds" % (seconds))

""" ## Gravity removal. """
# Remove gravity to complete dataset.
x_nograv, y_nograv, z_nograv = remove_gravity(S_DS)
S_DS["x_nograv"] = x_nograv
S_DS["y_nograv"] = y_nograv
S_DS["z_nograv"] = z_nograv

""" Plot difference with and without gravity """
# fig_1, axs_1 = plt.subplots(2,3, figsize=(25,10))
# axs_1[0,0].plot(S_DS["realtime"], S_DS["x"])
# axs_1[0,1].plot(S_DS["realtime"], S_DS["y"])
# axs_1[0,2].plot(S_DS["realtime"], S_DS["z"])
# axs_1[1,0].plot(S_DS["realtime"], S_DS["x_nograv"])
# axs_1[1,1].plot(S_DS["realtime"], S_DS["y_nograv"])
# axs_1[1,2].plot(S_DS["realtime"], S_DS["z_nograv"])

# """## Segmentation."""
# 
# From reference: 
#   A Comparative Study on Human Activity
#   Recognition Using Inertial Sensors in a Smartphone
sampling_freq = 200 # 200 samples per second.
window_size = 5 # 5 Seconds
segment_size = sampling_freq * window_size

segments = segment_data(segment_size, S_DS)
print("Segments: ", len(segments))

"""## Features Extraction.

### Magnitude
"""

for k in segments:
  seg = segments[k]['data']
  seg["mag"] = get_magnitudes(seg, nograv=True)

segments_df = pd.DataFrame(segments).transpose()
for i in range(len(segments_df)):
    if(len(segments_df["class"].iloc[i]) > 1):
        print(segments_df["class"].iloc[i]) # Segment with more than 1 class.

"""### Features"""

features = {} 

for k in segments:
  features[k] = get_features(segments[k]['data'])

fts = pd.DataFrame(features).transpose()
# print(fts)

# Each five seconds the predicted clas should be updated?
# or that predicted class must be updated each time data from the
# accelerometer is taken? i.e. update the class predicted, let's say
# that the sampling rate is 200Hz, them update 200 times per second.

# """# Test correlation"""
# 
# """Get features globally, i.e. of all dataset.
# 
# #***TODO***
# - [ ] Get features per class.
# - [ ] Plot features per class on same scatter plot.
# - [ ] Quntify results and compare between UCI and Heterogeneity.]
# - [ ] Segment per class and compare.
# 
# ## Clasification. """
